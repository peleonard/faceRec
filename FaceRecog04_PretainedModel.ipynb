{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading the necessay packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 125, 125, 3)\n",
      "(93,)\n",
      "(25, 125, 125, 3)\n",
      "(25,)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# load training and test data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "\n",
    "# resize input data to be 125*125\n",
    "size = (125, 125)\n",
    "\n",
    "data_train = pickle.load(open(\"data_dumped/image_data_train224.pkl\",\"rb\"))\n",
    "data_test = pickle.load(open(\"data_dumped/image_data_test224.pkl\",\"rb\"))\n",
    "class_list = pickle.load(open(\"data_dumped/class_list.pkl\", \"rb\"))\n",
    "\n",
    "# the data structure in image_data_train224.pkl\n",
    "# it is a list of (image, label) tuple, each image is a matrix of (224, 224, 3)\n",
    "\n",
    "X_train = np.array([cv2.resize(x[0], size)/255. for x in data_train])\n",
    "X_test = np.array([cv2.resize(x[0], size)/255. for x in data_test])\n",
    "\n",
    "Y_train = np.array([x[1] for x in data_train])\n",
    "Y_test = np.array([x[1] for x in data_test])\n",
    "\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_test.shape\n",
    "print Y_test.shape\n",
    "print X_train.max()\n",
    "print X_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "We load the saved (pretrained) models in file 02 and 03.\n",
    "1. file02: model 1, i.e. simple model, part of VGG, test accuracy on LFW: 0.51, training time shorter\n",
    "2. file03: model 2, i.e. mobileNet, test accuracy on LFW: 0.64, training time longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join('saved_models')\n",
    "model_name1 = 'keras_lfw_trained_model.h5'\n",
    "model_name2 = 'keras_lfw_trained_model_150_mobileNet.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_path = os.path.join(save_dir, model_name1)\n",
    "model_simple = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 125, 125, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 123, 123, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 59, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               27558400  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 158)               81054     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 158)               0         \n",
      "=================================================================\n",
      "Total params: 27,705,022\n",
      "Trainable params: 27,705,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'conv2d_17', u'activation_25', u'conv2d_18', u'activation_26', u'max_pooling2d_9', u'dropout_13', u'conv2d_19', u'activation_27', u'conv2d_20', u'activation_28', u'max_pooling2d_10', u'dropout_14', u'flatten_5', u'dense_9', u'activation_29', u'dropout_15', u'dense_10', u'activation_30']\n"
     ]
    }
   ],
   "source": [
    "print [l.name for l in model_simple.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "layer_name = 'activation_29'\n",
    "get_embedding_layer_output = K.function([model_simple.layers[0].input, K.learning_phase()],\n",
    "                                        [model_simple.get_layer(layer_name).output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test the new model with one 'random' image\n",
    "by >> x = np.random.rand(1,125,125,3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "x = np.random.rand(1,125,125,3)\n",
    "layer_output_test = get_embedding_layer_output([x, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 512)\n",
      "(1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "# Note that 0 refers to test, 1 refers to the training\n",
    "print np.array(get_embedding_layer_output([x, 0])).shape\n",
    "print np.array(get_embedding_layer_output([x, 1])).shape\n",
    "# get_embedding_layer_output([x, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "       0.      , 4.329412, 0.      , 0.      ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output_test[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now using the real training and test data\n",
    "Note we include keras.function.learning_phase(), 1 means training, 0 means test.\n",
    "\n",
    "<font color='red'>**However**</font>, we use static = 0 mode, in our case. There are three modes. It would affect some layers, e.g. the batch-normalization (BN) layer, dropout layer, etc. and then the final accuracy.\n",
    "One could refer to the [blog](http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 512)\n",
      "(25, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_embedding = get_embedding_layer_output([X_train, ])[0]\n",
    "X_test_embedding = get_embedding_layer_output([X_test, 0])[0]\n",
    "\n",
    "print X_train_embedding.shape\n",
    "print X_test_embedding.shape\n",
    "\n",
    "plt.hist(X_train_embedding.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of VGG:\n",
      "training accuracy:  1.0\n",
      "test accuracy:  0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lzq/anaconda3/envs/py27_faceRec/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lzq/anaconda3/envs/py27_faceRec/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# it is identical to only optimize over the top layer\n",
    "# previously the best we can get is 0.72 accuracy\n",
    "\n",
    "model = LR()\n",
    "model.fit(X_train_embedding, Y_train)\n",
    "print \"Part of VGG:\\ntraining accuracy: \", model.score(X_train_embedding, Y_train)\n",
    "print \"test accuracy: \", model.score(X_test_embedding, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model 2:  MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 125, 125, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 127, 127, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 63, 63, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 65, 65, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 63, 63, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 63, 63, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 154)         157850    \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 154)         0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 154)               0         \n",
      "=================================================================\n",
      "Total params: 3,386,714\n",
      "Trainable params: 3,364,826\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "model_path_mobileNet = os.path.join(save_dir, model_name2)\n",
    "model_mobilenet = load_model(model_path_mobileNet, custom_objects={'relu6': mobilenet.relu6,\n",
    "                                                                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "\n",
    "print model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "#### batch normalization (BN) layer\n",
    "To increase the stability of a neural network, batch normalization normalizes the output of a previous \n",
    "activation layer by subtracting the batch mean and dividing by the batch standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout_13/keras_learning_phase:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "print K.learning_phase()\n",
    "\n",
    "layer_name_mobilenet = 'global_average_pooling2d_1'\n",
    "get_embedding_layer_output_mobilenet = K.function([model_mobilenet.layers[0].input, K.learning_phase()],\n",
    "                                                  [model_mobilenet.get_layer(layer_name_mobilenet).output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 1024)\n",
      "(25, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_embedding_mobilenet = get_embedding_layer_output_mobilenet([X_train, 0])[0]\n",
    "X_test_embedding_mobilenet = get_embedding_layer_output_mobilenet([X_test, 0])[0]\n",
    "\n",
    "print X_train_embedding_mobilenet.shape\n",
    "print X_test_embedding_mobilenet.shape\n",
    "\n",
    "plt.hist(X_train_embedding_mobilenet.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained MobileNet:\n",
      "training accuracy:  0.7634408602150538\n",
      "test accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "# it is identical to only optimize over the top layer\n",
    "\n",
    "model = LR()\n",
    "model.fit(X_train_embedding_mobilenet, Y_train)\n",
    "print \"Pretrained MobileNet:\\ntraining accuracy: \", model.score(X_train_embedding_mobilenet, Y_train)\n",
    "print \"test accuracy: \", model.score(X_test_embedding_mobilenet, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: simple logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisic Regression\n",
      " training accuracy:  1.0\n",
      "test accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "model = LR()\n",
    "model.fit(X_train.reshape(X_train.shape[0], -1), Y_train)\n",
    "print \"Logisic Regression\\n training accuracy: \", model.score(X_train.reshape(X_train.shape[0],-1), Y_train)\n",
    "print \"test accuracy: \", model.score(X_test.reshape(X_test.shape[0],-1), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion: \n",
    "1. Pretraining may help deep network training, but it requires longer and finer training. A finer transfering would be applied in the \"FaceRecog05_*.\".\n",
    "2. In our case, a noisy pretraining, part of VGG and MobileNet, cannot beat even logistic regression, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27_faceRec]",
   "language": "python",
   "name": "conda-env-py27_faceRec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
